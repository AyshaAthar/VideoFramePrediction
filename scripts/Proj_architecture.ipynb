{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj_architecture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TGEbx4dCRZ7R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from MovingMNIST import MovingMNIST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_set = MovingMNIST(root='.data/mnist', train=True, download=True)\n",
        "test_set = MovingMNIST(root='.data/mnist', train=False, download=True)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 dataset=train_set,\n",
        "                 batch_size=batch_size,\n",
        "                 \n",
        "                 shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                dataset=test_set,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZyUfMc1RdK8",
        "outputId": "db6b1739-6191-4290-c7dd-62e1979bf585"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/tychovdo/MovingMNIST/raw/master/mnist_test_seq.npy.gz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, _ = next(iter(train_loader))\n",
        "print(input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIFXGuppRjjv",
        "outputId": "d3c4c975-9a3c-42f1-b16e-72d51fd65b7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 10, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
        "print('==>>> total testing batch number: {}'.format(len(test_loader)))\n",
        "\n",
        "for seq, seq_target in train_loader:\n",
        "    print('--- Sample')\n",
        "    print('Input:  ', seq.shape)\n",
        "    print('Target: ', seq_target.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goNhIrWBRoeM",
        "outputId": "c0c4f681-7db9-4de8-d177-7cfb6fecd4e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==>>> total trainning batch number: 90\n",
            "==>>> total testing batch number: 10\n",
            "--- Sample\n",
            "Input:   torch.Size([100, 10, 64, 64])\n",
            "Target:  torch.Size([100, 10, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias,mode=\"zeros\"):\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias = bias\n",
        "        self.mode = mode\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "        \n",
        "       \n",
        "        \n",
        "\n",
        "    def forward(self, x, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "        x = x.to(device)\n",
        "        h_cur = h_cur.to(device)\n",
        "        # print(x.size())\n",
        "        # print(h_cur.size())\n",
        "        concat_input_hcur = torch.cat([x, h_cur], dim=1) \n",
        "        concat_input_hcur = concat_input_hcur.to(device)\n",
        "\n",
        "        concat_input_hcur_conv = self.conv(concat_input_hcur)\n",
        "        concat_input_hcur_conv = concat_input_hcur_conv.to(device)\n",
        "\n",
        "        cc_input_gate, cc_forget_gate, cc_output_gate, cc_output = torch.split(concat_input_hcur_conv, self.hidden_dim, dim=1)\n",
        "        # print(\"cci\",cc_input_gate.shape)\n",
        "        # print(\"ccf\",cc_forget_gate.shape)\n",
        "        # print(\"ccog\",cc_output_gate.shape)\n",
        "        # print(\"cco\",cc_output.shape)\n",
        "        # print(\"cccur\",c_cur.shape)\n",
        "        # print(\"wci\",self.W_ci.shape)\n",
        "        \n",
        "        input_gate = torch.sigmoid(cc_input_gate +  c_cur)\n",
        "\n",
        "        forget_gate = torch.sigmoid(cc_forget_gate +  c_cur)\n",
        "\n",
        "        output = torch.tanh(cc_output)\n",
        "\n",
        "        c_next = forget_gate * c_cur + input_gate * output\n",
        "\n",
        "        output_gate = torch.sigmoid(cc_output_gate +  c_next)\n",
        "\n",
        "        h_next = output * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_state(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        \"\"\" Initializing hidden and cell state \"\"\"\n",
        "        if(self.mode == \"zeros\"):\n",
        "            h = torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
        "            c = torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
        "        elif(self.mode == \"random\"):\n",
        "            h = torch.randn(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
        "            c = torch.randn(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device)\n",
        "        elif(self.mode == \"learned\"):\n",
        "            h = self.learned_h.repeat(batch_size, 1, height, width, device=self.conv.weight.device)\n",
        "            c = self.learned_c.repeat(batch_size, 1, height, width, device=self.conv.weight.device)\n",
        "        \n",
        "        return h, c\n",
        "\n",
        "        \n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "    \"\"\" \n",
        "    Custom LSTM for images. Batches of images are fed to a Conv LSTM\n",
        "    \n",
        "    Args:\n",
        "    -----\n",
        "    input_dim: integer\n",
        "        Number of channels of the input.\n",
        "    hidden_dim: integer\n",
        "        dimensionality of the states in the cell\n",
        "    kernel_size: tuple\n",
        "        size of the kernel for convolutions\n",
        "    num_layers: integer\n",
        "        number of stacked LSTMS\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        \n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "       \n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "        classifier_in_dim= (self.hidden_dim[0]*16*16)\n",
        "        classifier_output_dim = output_label_size\n",
        "\n",
        "        # FC-classifier\n",
        "        self.classifier = nn.Linear(classifier_in_dim, classifier_output_dim)\n",
        "\n",
        "        conv_lstms  = []\n",
        "        # iterating over no of layers\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
        "\n",
        "            conv_lstms.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.conv_lstms = nn.ModuleList(conv_lstms)\n",
        "\n",
        "    def forward(self, x, hidden_state=None):\n",
        "       \n",
        "\n",
        "        x=x.unsqueeze(dim=1)\n",
        "        b, _, _, h, w = x.size()\n",
        "\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            hidden_state = self._init_hidden(batch_size=b,\n",
        "                                             image_size=(h, w))\n",
        "\n",
        "        \n",
        "        cur_layer_input = x\n",
        "        output_list = []\n",
        "        x_len = x.size(1)\n",
        "        \n",
        "\n",
        "        # iterating over no of layers\n",
        "        for i in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[i]\n",
        "            each_layer_output = []\n",
        "            # iterating over sequence length\n",
        "\n",
        "            for t in range(x_len):\n",
        "                h, c = self.conv_lstms[i](x=cur_layer_input[:, t, :, :, :],cur_state=[h, c])\n",
        "                each_layer_output.append(h)\n",
        "\n",
        "            stacked_layer_output = torch.stack(each_layer_output, dim=1)\n",
        "            cur_layer_input = stacked_layer_output\n",
        "\n",
        "            output_list.append(stacked_layer_output)\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            output_list = output_list[-1:]\n",
        "\n",
        "        batch_shape = output_list[-1].shape[0]\n",
        "\n",
        "        return torch.stack(each_layer_output), (h, c)\n",
        "\n",
        "    def _init_hidden(self, batch_size, image_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.conv_lstms[i].init_state(batch_size, image_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param"
      ],
      "metadata": {
        "id": "2nwN-a5kRvWU"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVNlYWFURsDw",
        "outputId": "56ff5559-267c-4b76-ed9e-4b9a3a7db671"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstLayerEncBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3,stride=1,padding=(1, 1))\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3,stride=1,padding=(1, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv2(self.relu(self.conv1(x)))\n",
        "\n",
        "class FirstEncoder(nn.Module):\n",
        "    def __init__(self, chs):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([FirstLayerEncBlock(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        layers = []\n",
        "        print(\"hello\")\n",
        "        print(x.shape)\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            print(x.shape)\n",
        "            \n",
        "            x = self.pool(x)\n",
        "            layers.append(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0wNXXXeoSOjw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstLayerDecBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.ConvTranspose2d(in_ch, out_ch, 3,stride=2,padding=(1, 1))\n",
        "        self.conv2 = nn.ConvTranspose2d(out_ch, out_ch, 2,stride=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv2((self.conv1(x)))\n",
        "\n",
        "class FirstDecoder(nn.Module):\n",
        "    def __init__(self, chs):\n",
        "        super().__init__()\n",
        "        self.dec_blocks = nn.ModuleList([FirstLayerDecBlock(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        layers = []\n",
        "        print(\"hello\")\n",
        "        print(x.shape)\n",
        "        for block in self.dec_blocks:\n",
        "            x = block(x)\n",
        "            print(x.shape)\n",
        "            \n",
        "           \n",
        "        return x"
      ],
      "metadata": {
        "id": "F29_Ra-xViBE"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1, _ = next(iter(train_loader))\n",
        "print(input1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwNnjX0kUWe1",
        "outputId": "229461c6-c3ae-48a0-c6b8-ea53e907daae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 10, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_chs=(1,16,64)\n",
        "e= FirstEncoder(enc_chs)\n",
        "e.to(device)\n",
        "x = torch.randn((100,1, 64, 64))\n",
        "y1= e(input1[:,9:,:,:].float().cuda())\n",
        "print(y1.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf66OChmUZ8D",
        "outputId": "fb7a2b52-b526-4305-ac4f-6aa632172d9a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 1, 64, 64])\n",
            "torch.Size([100, 16, 64, 64])\n",
            "torch.Size([100, 64, 32, 32])\n",
            "torch.Size([100, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (28,28)\n",
        "output_label_size = 10"
      ],
      "metadata": {
        "id": "0SzulpM5WOTa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model= ConvLSTM(input_dim= 64, hidden_dim = 64, kernel_size = (5,5), num_layers= 1)\n",
        "if torch.cuda.is_available():\n",
        "    conv_model.to(device)"
      ],
      "metadata": {
        "id": "6wJdhuHYWQca"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtFtGIrVWS7i",
        "outputId": "e31ec78e-37ce-4ce1-95fd-fc0781ace0d6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvLSTM(\n",
            "  (classifier): Linear(in_features=16384, out_features=10, bias=True)\n",
            "  (conv_lstms): ModuleList(\n",
            "    (0): ConvLSTMCell(\n",
            "      (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=conv_model(y1)\n",
        "print(c[1][0].size())\n",
        "convlstm_out=c[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4wUTgxVWTnr",
        "outputId": "28a1002c-7871-4793-ef14-da21c33ec974"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_chs=(64,16,1)\n",
        "d= FirstDecoder(dec_chs)\n",
        "d.to(device)\n",
        "\n",
        "cv=d(convlstm_out)\n",
        "print(cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xEm2s-FWwhl",
        "outputId": "efffb4f6-b3f3-479d-ba20-8fdc5f75c44f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 64, 16, 16])\n",
            "torch.Size([100, 16, 32, 32])\n",
            "torch.Size([100, 1, 64, 64])\n",
            "torch.Size([100, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_chs1=(64,128)\n",
        "e1= FirstEncoder(enc_chs1)\n",
        "e1.to(device)\n",
        "y2= e1(y1)\n",
        "print(y2.shape)\n"
      ],
      "metadata": {
        "id": "nTkgLpGkbZY9",
        "outputId": "59b10228-441b-4abc-de1a-60bce1f86a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 64, 16, 16])\n",
            "torch.Size([100, 128, 16, 16])\n",
            "torch.Size([100, 128, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model1= ConvLSTM(input_dim= 128, hidden_dim = 128, kernel_size = (5,5), num_layers= 1)\n",
        "if torch.cuda.is_available():\n",
        "    conv_model1.to(device)"
      ],
      "metadata": {
        "id": "Kww3Qqpvdo8x"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1=conv_model1(y2)\n",
        "print(c1[1][0].size())\n",
        "convlstm_out1=c1[1][0]"
      ],
      "metadata": {
        "id": "tRsQiy4HcqbM",
        "outputId": "31b1e51e-961d-401a-d915-64f9bae0f136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 128, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_chs1=(128,64)\n",
        "d2= FirstDecoder(dec_chs1)\n",
        "d2.to(device)\n",
        "\n",
        "cv1=d2(convlstm_out1)\n",
        "print(cv1.shape)"
      ],
      "metadata": {
        "id": "fA93j2NFfwaP",
        "outputId": "9532e819-52df-4c56-9ffa-a4489d54e58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 128, 8, 8])\n",
            "torch.Size([100, 64, 16, 16])\n",
            "torch.Size([100, 64, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_chs2=(128,256)\n",
        "e2= FirstEncoder(enc_chs2)\n",
        "e2.to(device)\n",
        "y3= e2(y2)\n",
        "print(y3.shape)\n"
      ],
      "metadata": {
        "id": "jRDj1oTmgXWG",
        "outputId": "64a97513-0bfb-44f0-9b64-b09188ebaa63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 128, 8, 8])\n",
            "torch.Size([100, 256, 8, 8])\n",
            "torch.Size([100, 256, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model2= ConvLSTM(input_dim= 256, hidden_dim = 256, kernel_size = (5,5), num_layers= 1)\n",
        "if torch.cuda.is_available():\n",
        "    conv_model2.to(device)"
      ],
      "metadata": {
        "id": "uDlod2kcgkTB"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c2=conv_model2(y3)\n",
        "print(c2[1][0].size())\n",
        "convlstm_out2=c2[1][0]"
      ],
      "metadata": {
        "id": "1KqnhYf7gvAw",
        "outputId": "bc55ed0a-12fd-4e60-d6e1-39f6d12fbcdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 256, 4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_chs2=(256,128)\n",
        "d3= FirstDecoder(dec_chs2)\n",
        "d3.to(device)\n",
        "\n",
        "cv2=d3(convlstm_out2)\n",
        "print(cv2.shape)"
      ],
      "metadata": {
        "id": "gJtRmC6hg5Xn",
        "outputId": "0587151c-be10-4500-cbd9-b00df1a6bf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "torch.Size([100, 256, 4, 4])\n",
            "torch.Size([100, 128, 8, 8])\n",
            "torch.Size([100, 128, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstLayerDecBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.ConvTranspose2d(in_ch, out_ch, 3,stride=2,padding=(1, 1))\n",
        "        self.conv2 = nn.ConvTranspose2d(out_ch, out_ch, 2,stride=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv2((self.conv1(x)))\n",
        "\n",
        "class FirstDecoder(nn.Module):\n",
        "    def __init__(self, chs):\n",
        "        super().__init__()\n",
        "        self.dec_blocks = nn.ModuleList([FirstLayerDecBlock(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        layers = []\n",
        "        print(\"hello\")\n",
        "        print(x.shape)\n",
        "        for block in self.dec_blocks:\n",
        "            x = block(x)\n",
        "            print(x.shape)\n",
        "            \n",
        "           \n",
        "        return x"
      ],
      "metadata": {
        "id": "k6qIboXekH2u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}