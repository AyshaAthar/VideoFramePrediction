{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GQF1IAGSXBmo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from dataset import MNIST_Moving\n",
    "\n",
    "from encoder import Embedded_Encoder\n",
    "from decoder import Embedded_Decoder\n",
    "from conv_lstm import ConvLSTM\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-frR5EzXMEn",
    "outputId": "fe3dc13b-5ea8-41c4-e192-2be2374fad22"
   },
   "outputs": [],
   "source": [
    "train_set = MNIST_Moving(root='.data/mnist', train=True, download=True)\n",
    "test_set = MNIST_Moving(root='.data/mnist', train=False, download=True)\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 \n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK5dQ8pHXOtH",
    "outputId": "6e74e2e0-c049-4a19-db61-b667f00403c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input is  torch.Size([100, 20, 1, 64, 64])\n",
      "The shape of the video seq is torch.Size([20, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "input= next(iter(train_loader))\n",
    "print(\"The shape of the input is \", input.shape)\n",
    "\n",
    "vid_seq = input[0]\n",
    "print(\"The shape of the video seq is\", vid_seq.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF-rceP8dWAe",
    "outputId": "ff9e1098-6011-48b3-ddf0-296d64c72c75"
   },
   "outputs": [],
   "source": [
    "# ModelEncoder = Embedded_Encoder(device)\n",
    "# print(\"The input is of the size\",vid_seq.shape)\n",
    "\n",
    "# encoderLayerOutputs=ModelEncoder(vid_seq.float().cuda())\n",
    "# #These features or outputs from each encoder can be then passed on to the convlstm \n",
    "\n",
    "# print(\"The outputs of each encoder in the embedded encoder:\")\n",
    "# for ftr in encoderLayerOutputs: print(ftr.shape)\n",
    "\n",
    "\n",
    "# ModelDecoder=Embedded_Decoder()\n",
    "# print(\"The input of the embedded decoder is the output from the last encoder in the embedded encoder\",encoderLayerOutputs[-1].shape)\n",
    "# decoderLayerOutputs=ModelDecoder(encoderLayerOutputs[-1])\n",
    "# print(\"The outputs of each encoder in the embedded decoder:\")\n",
    "# for ftr in decoderLayerOutputs: print(ftr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 64, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "input_seq = torch.rand(((20, 1, 64, 64))).to(device)\n",
    "model(input_seq).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0jJdJC3nXBQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pMTmv2H6nJxe"
   },
   "outputs": [],
   "source": [
    "abc = torch.rand((1, 64, 16, 16))\n",
    "abc_3 = torch.rand((1, 256, 4, 4))\n",
    "\n",
    "llm = conv_model_FirstEncoder(abc)\n",
    "llm_3 = conv_model_ThirdEncoder(abc_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\"\n",
    "# def training(criterion):\n",
    "# #     Seq of 20 images\n",
    "#     input_seq = torch.rand(((20, 1, 64, 64)))\n",
    "#     embd_model = Embedded_Encoder(device)\n",
    "#     embds = embd_model(input_seq.float().cuda())\n",
    "#     lstm_1, (h_1, c_1) = conv_model_FirstEncoder(embds[0])\n",
    "#     lstm_2, (h_2, c_2) = conv_model_SecondEncoder(embds[1])\n",
    "#     lstm_3, (h_3, c_3) = conv_model_ThirdEncoder(embds[2])\n",
    "    \n",
    "#     print(lstm_1.shape)\n",
    "#     print(lstm_2.shape)\n",
    "#     print(lstm_3.shape)\n",
    "#     decoder = Embedded_Decoder(device)\n",
    "#     out_1 = decoder.firstDecoder(lstm_3.squeeze())\n",
    "#     print(out_1.shape)\n",
    "#     in_2 = torch.cat((out_1, lstm_2.squeeze()), 1)\n",
    "#     out_2 = decoder.secondDecoder(in_2)\n",
    "#     print(out_2.shape)\n",
    "#     in_3 = torch.cat((out_2, lstm_1.squeeze()), 1)\n",
    "#     out_3 = decoder.thirdDecoder(in_3)\n",
    "#     print(out_3.shape)\n",
    "    \n",
    "#     loss = criterion(input_seq[10:, :, :, :].to(device), out_3[10:, :, :, :])\n",
    "#     print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, criterion, epoch, device):\n",
    "    \"\"\" Training a model for one epoch \"\"\"\n",
    "    \n",
    "    loss_list = []\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, full_seq in progress_bar:\n",
    "       \n",
    "        full_seq = full_seq.squeeze(0).type(torch.FloatTensor).to(device)\n",
    "        target_seq = full_seq[10:, :, :, :]\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass only to get logits/output\n",
    "        outputs = model(full_seq)\n",
    "        outputs = outputs.to(device)\n",
    "         \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs[10:, :, :, :], target_seq)\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "         \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} Iter {i+1}: loss {loss.item():.5f}. \")\n",
    "        \n",
    "    mean_loss = np.mean(loss_list)\n",
    "    return mean_loss, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Iter 439: loss 1147.03320. :   5%|‚ñè   | 439/9000 [00:39<12:48, 11.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28645/2767331045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_28645/2990253962.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, criterion, epoch, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} Iter {i+1}: loss {loss.item():.5f}. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch(model, train_loader, optimizer, criterion, 0, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.firstDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Encoder_Decoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
